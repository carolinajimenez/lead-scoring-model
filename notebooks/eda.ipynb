{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_cleaning import DataCleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning = DataCleaning(main_path=\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (61639, 10)\n",
      "\n",
      "         Id       First Name          Use Case   Source     Status  \\\n",
      "0  23okrabh              NaN  Corporate Events  Inbound  Nurturing   \n",
      "1       NaN  Taylor1 Harris1               NaN  Inbound  Discarded   \n",
      "2  hbzt0kp1   Alex6 Jackson3               NaN  Inbound  Nurturing   \n",
      "3  velluwdq  Bailey2 Taylor6  Corporate Events  Inbound  Discarded   \n",
      "4       NaN    Drew5 Wilson5  Corporate Events  Inbound  Nurturing   \n",
      "\n",
      "  Discarded/Nurturing Reason    Acquisition Campaign Created Date  Converted  \\\n",
      "0                    Not Fit                     NaN   2018-05-26          0   \n",
      "1                Not feeling  Event Management Guide   2018-10-17          0   \n",
      "2                 Competitor                     NaN   2019-03-29          0   \n",
      "3                 Not Target                     NaN   2018-05-26          0   \n",
      "4                 Competitor                     NaN   2018-10-17          0   \n",
      "\n",
      "      City  \n",
      "0  Chicago  \n",
      "1   Denver  \n",
      "2   Denver  \n",
      "3      NaN  \n",
      "4      NaN  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61639 entries, 0 to 61638\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Id                          43972 non-null  object\n",
      " 1   First Name                  53240 non-null  object\n",
      " 2   Use Case                    44918 non-null  object\n",
      " 3   Source                      60293 non-null  object\n",
      " 4   Status                      61639 non-null  object\n",
      " 5   Discarded/Nurturing Reason  45169 non-null  object\n",
      " 6   Acquisition Campaign        25047 non-null  object\n",
      " 7   Created Date                61639 non-null  object\n",
      " 8   Converted                   61639 non-null  int64 \n",
      " 9   City                        34929 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 4.7+ MB\n",
      "None\n",
      "\n",
      "\n",
      "Column index - Number of unique values for each column.\n",
      "Id                            43972\n",
      "First Name                    53240\n",
      "Use Case                          5\n",
      "Source                            6\n",
      "Status                           12\n",
      "Discarded/Nurturing Reason       13\n",
      "Acquisition Campaign             71\n",
      "Created Date                    591\n",
      "Converted                         2\n",
      "City                             20\n",
      "dtype: int64\n",
      "Are there duplicates?: True\n",
      "        Id First Name          Use Case   Source     Status  \\\n",
      "34     NaN        NaN     Sports Events  Inbound  Discarded   \n",
      "48     NaN        NaN     Sports Events  Inbound  Discarded   \n",
      "99     NaN        NaN     Sports Events  Inbound  Discarded   \n",
      "149    NaN        NaN     Sports Events  Inbound        New   \n",
      "194    NaN        NaN     Sports Events  Inbound        New   \n",
      "...    ...        ...               ...      ...        ...   \n",
      "61429  NaN        NaN  Corporate Events  Inbound  Qualified   \n",
      "61477  NaN        NaN     Sports Events  Inbound  Discarded   \n",
      "61479  NaN        NaN     Sports Events  Inbound  Discarded   \n",
      "61515  NaN        NaN     Sports Events  Inbound  Nurturing   \n",
      "61631  NaN        NaN     Sports Events  Inbound        New   \n",
      "\n",
      "      Discarded/Nurturing Reason Acquisition Campaign Created Date  Converted  \\\n",
      "34                    Not Target                  NaN   2018-10-17          0   \n",
      "48                    Not Target                  NaN   2018-01-01          0   \n",
      "99                    Not Target                  NaN   2018-01-01          0   \n",
      "149                          NaN                  NaN   2019-04-28          0   \n",
      "194                          NaN                  NaN   2019-04-28          0   \n",
      "...                          ...                  ...          ...        ...   \n",
      "61429                        NaN                  NaN   2020-09-26          1   \n",
      "61477                 Not Target                  NaN   2020-09-26          0   \n",
      "61479             Duplicate/Test                  NaN   2020-09-26          0   \n",
      "61515       Not the right moment                  NaN   2020-09-26          0   \n",
      "61631                        NaN                  NaN   2020-10-27          0   \n",
      "\n",
      "      City  \n",
      "34     NaN  \n",
      "48     NaN  \n",
      "99     NaN  \n",
      "149    NaN  \n",
      "194    NaN  \n",
      "...    ...  \n",
      "61429  NaN  \n",
      "61477  NaN  \n",
      "61479  NaN  \n",
      "61515  NaN  \n",
      "61631  NaN  \n",
      "\n",
      "[1576 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "leads_df = data_cleaning.load_dataset(dataset_path=\"leads.csv\")\n",
    "data_cleaning.inspect_dataset(leads_df)\n",
    "data_cleaning.identify_columns_with_single_value(leads_df)\n",
    "data_cleaning.identify_row_with_duplicate_data(leads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (6130, 9)\n",
      "\n",
      "         Id              Use Case       Status Created Date  Close Date  \\\n",
      "0  doqyhjtv  Educational Seminars   Closed Won   2019-11-17  2019-11-17   \n",
      "1       NaN         Sports Events  Closed Lost   2019-11-24  2019-11-25   \n",
      "2       NaN         Sports Events  Closed Lost   2019-11-24  2019-11-25   \n",
      "3  cturqi48      Corporate Events   Closed Won   2019-05-07  2019-05-07   \n",
      "4       NaN         Sports Events  Closed Lost   2019-11-17  2019-11-25   \n",
      "\n",
      "   Price    Discount code               Pain  Loss Reason  \n",
      "0  300.0       SAVEMORE50         operations          NaN  \n",
      "1  150.0              NaN         operations        price  \n",
      "2  768.0      HALFYEAR20G         operations  no response  \n",
      "3  240.0  DISCOUNT50POWER  financial control          NaN  \n",
      "4  240.0     SAVEMONTH50G  financial control  no response  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6130 entries, 0 to 6129\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             4962 non-null   object \n",
      " 1   Use Case       6093 non-null   object \n",
      " 2   Status         6130 non-null   object \n",
      " 3   Created Date   6130 non-null   object \n",
      " 4   Close Date     6130 non-null   object \n",
      " 5   Price          5765 non-null   float64\n",
      " 6   Discount code  4431 non-null   object \n",
      " 7   Pain           5261 non-null   object \n",
      " 8   Loss Reason    2364 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 431.1+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Column index - Number of unique values for each column.\n",
      "Id               4924\n",
      "Use Case            5\n",
      "Status              6\n",
      "Created Date      420\n",
      "Close Date        440\n",
      "Price              95\n",
      "Discount code     112\n",
      "Pain                4\n",
      "Loss Reason         8\n",
      "dtype: int64\n",
      "Are there duplicates?: True\n",
      "       Id              Use Case       Status Created Date  Close Date  Price  \\\n",
      "286   NaN         Sports Events       Demo 1   2019-09-07  2020-01-26    NaN   \n",
      "2503  NaN      Corporate Events   Closed Won   2019-11-05  2019-11-05  360.0   \n",
      "2730  NaN      Corporate Events   Closed Won   2019-11-05  2019-11-05  360.0   \n",
      "2789  NaN      Corporate Events   Closed Won   2019-06-05  2019-06-05  324.0   \n",
      "2824  NaN      Corporate Events   Closed Won   2019-11-05  2019-11-05  360.0   \n",
      "3093  NaN  Educational Seminars       Demo 1   2019-02-06  2020-01-26    NaN   \n",
      "4075  NaN         Sports Events       Demo 1   2018-06-05  2018-06-05    NaN   \n",
      "4968  NaN      Wedding Planning   Closed Won   2019-06-16  2019-06-16    NaN   \n",
      "4984  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4985  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4986  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4987  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4988  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4989  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "4990  NaN      Wedding Planning   Closed Won   2019-05-11  2019-05-11    NaN   \n",
      "5338  NaN      Wedding Planning   Closed Won   2019-04-23  2019-04-23    NaN   \n",
      "5339  NaN      Wedding Planning   Closed Won   2019-04-23  2019-04-23    NaN   \n",
      "5346  NaN      Wedding Planning   Closed Won   2019-04-23  2018-09-07  100.0   \n",
      "5348  NaN      Wedding Planning   Closed Won   2019-04-23  2018-11-24  100.0   \n",
      "5414  NaN      Wedding Planning   Closed Won   2019-04-23  2018-10-07  100.0   \n",
      "5415  NaN      Wedding Planning   Closed Won   2019-04-23  2018-11-19  100.0   \n",
      "5417  NaN      Wedding Planning   Closed Won   2019-04-23  2019-02-09    NaN   \n",
      "5418  NaN      Wedding Planning   Closed Won   2019-04-23  2019-02-09    NaN   \n",
      "5420  NaN      Wedding Planning   Closed Won   2019-04-23  2019-02-09    NaN   \n",
      "5422  NaN      Wedding Planning   Closed Won   2019-04-23  2019-02-20    NaN   \n",
      "5423  NaN      Wedding Planning   Closed Won   2019-04-23  2019-02-20    NaN   \n",
      "5432  NaN      Wedding Planning   Closed Won   2019-04-23  2018-12-29    NaN   \n",
      "5434  NaN      Wedding Planning   Closed Won   2019-04-23  2019-03-18    NaN   \n",
      "5457  NaN      Wedding Planning  Closed Lost   2019-05-25  2019-10-26    NaN   \n",
      "5459  NaN      Wedding Planning  Closed Lost   2019-05-25  2019-10-26    NaN   \n",
      "5506  NaN      Wedding Planning   Closed Won   2019-04-23  2019-03-18    NaN   \n",
      "5507  NaN      Wedding Planning   Closed Won   2019-04-23  2019-03-18    NaN   \n",
      "5508  NaN      Wedding Planning   Closed Won   2019-04-23  2019-03-18    NaN   \n",
      "5509  NaN      Wedding Planning   Closed Won   2019-04-23  2019-03-18    NaN   \n",
      "5539  NaN      Wedding Planning  Closed Lost   2019-05-26  2019-10-26    NaN   \n",
      "5621  NaN      Wedding Planning   Closed Won   2019-05-26  2019-05-26    NaN   \n",
      "5671  NaN      Wedding Planning  Closed Lost   2019-04-24  2019-04-24    NaN   \n",
      "5690  NaN      Wedding Planning  Closed Lost   2019-05-26  2019-05-26    NaN   \n",
      "5810  NaN      Wedding Planning   Closed Won   2019-04-25  2019-02-23    NaN   \n",
      "5811  NaN      Wedding Planning   Closed Won   2019-04-25  2019-03-26    NaN   \n",
      "5812  NaN      Wedding Planning   Closed Won   2019-04-25  2019-03-26    NaN   \n",
      "5813  NaN      Wedding Planning   Closed Won   2019-04-25  2019-03-26    NaN   \n",
      "5814  NaN      Wedding Planning   Closed Won   2019-04-25  2019-02-23    NaN   \n",
      "5815  NaN      Wedding Planning   Closed Won   2019-04-25  2018-12-26    NaN   \n",
      "5816  NaN      Wedding Planning   Closed Won   2019-04-25  2018-12-26    NaN   \n",
      "5862  NaN      Wedding Planning   Closed Won   2019-06-25  2019-06-25    NaN   \n",
      "5921  NaN      Wedding Planning   Closed Won   2019-06-29  2019-06-28    0.0   \n",
      "5923  NaN      Wedding Planning   Closed Won   2019-06-29  2019-07-29    0.0   \n",
      "5926  NaN      Wedding Planning   Closed Won   2019-06-29  2019-03-11    0.0   \n",
      "5928  NaN      Wedding Planning   Closed Won   2019-06-29  2019-03-12    0.0   \n",
      "5930  NaN      Wedding Planning   Closed Won   2019-06-29  2019-03-13    0.0   \n",
      "5931  NaN      Wedding Planning   Closed Won   2019-06-29  2019-03-13    0.0   \n",
      "5957  NaN      Wedding Planning   Closed Won   2019-01-31  2019-01-31    NaN   \n",
      "5970  NaN      Wedding Planning   Closed Won   2019-05-19  2019-05-19    NaN   \n",
      "\n",
      "        Discount code                 Pain  Loss Reason  \n",
      "286               NaN  quality of delivery          NaN  \n",
      "2503  MONTHSAVE25DEAL    financial control          NaN  \n",
      "2730  MONTHSAVE25DEAL           operations          NaN  \n",
      "2789     10OFFREDUCED    financial control          NaN  \n",
      "2824  MONTHSAVE25DEAL           operations          NaN  \n",
      "3093              NaN           operations          NaN  \n",
      "4075              NaN                  NaN          NaN  \n",
      "4968              NaN                  NaN          NaN  \n",
      "4984              NaN                  NaN          NaN  \n",
      "4985              NaN                  NaN          NaN  \n",
      "4986              NaN                  NaN          NaN  \n",
      "4987              NaN                  NaN          NaN  \n",
      "4988              NaN                  NaN          NaN  \n",
      "4989              NaN                  NaN          NaN  \n",
      "4990              NaN                  NaN          NaN  \n",
      "5338              NaN                  NaN          NaN  \n",
      "5339              NaN                  NaN          NaN  \n",
      "5346              NaN                  NaN          NaN  \n",
      "5348              NaN                  NaN          NaN  \n",
      "5414              NaN                  NaN          NaN  \n",
      "5415              NaN                  NaN          NaN  \n",
      "5417              NaN                  NaN          NaN  \n",
      "5418              NaN                  NaN          NaN  \n",
      "5420              NaN                  NaN          NaN  \n",
      "5422              NaN                  NaN          NaN  \n",
      "5423              NaN                  NaN          NaN  \n",
      "5432              NaN                  NaN          NaN  \n",
      "5434              NaN                  NaN          NaN  \n",
      "5457              NaN                  NaN    no budget  \n",
      "5459              NaN                  NaN    no budget  \n",
      "5506              NaN                  NaN          NaN  \n",
      "5507              NaN                  NaN          NaN  \n",
      "5508              NaN                  NaN          NaN  \n",
      "5509              NaN                  NaN          NaN  \n",
      "5539              NaN                  NaN    no budget  \n",
      "5621              NaN                  NaN          NaN  \n",
      "5671              NaN                  NaN  no response  \n",
      "5690              NaN                  NaN  no response  \n",
      "5810              NaN                  NaN          NaN  \n",
      "5811              NaN                  NaN          NaN  \n",
      "5812              NaN                  NaN          NaN  \n",
      "5813              NaN                  NaN          NaN  \n",
      "5814              NaN                  NaN          NaN  \n",
      "5815              NaN                  NaN          NaN  \n",
      "5816              NaN                  NaN          NaN  \n",
      "5862              NaN                  NaN          NaN  \n",
      "5921              NaN                  NaN          NaN  \n",
      "5923              NaN                  NaN          NaN  \n",
      "5926              NaN                  NaN          NaN  \n",
      "5928              NaN                  NaN          NaN  \n",
      "5930              NaN                  NaN          NaN  \n",
      "5931              NaN                  NaN          NaN  \n",
      "5957              NaN                  NaN          NaN  \n",
      "5970              NaN                  NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "offers_df = data_cleaning.load_dataset(dataset_path=\"offers.csv\")\n",
    "data_cleaning.inspect_dataset(offers_df)\n",
    "data_cleaning.identify_columns_with_single_value(offers_df)\n",
    "data_cleaning.identify_row_with_duplicate_data(offers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the data we can observe:\n",
    "* There are more records per leads than per offers.\n",
    "* There are null values.\n",
    "* There are no columns with a single value.\n",
    "* There are rows that contain duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing rows - Shape: (60063, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leads_df = data_cleaning.delete_row_with_duplicate_data(leads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing rows - Shape: (6076, 9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offers_df = data_cleaning.delete_row_with_duplicate_data(offers_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
